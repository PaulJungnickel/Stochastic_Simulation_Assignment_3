{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Stochastic Simulation Assignment 3\n",
    "---\n",
    "\n",
    "### **Contributors**  \n",
    "- **Maarten Stork** - 15761770\n",
    "- **Paul Jungnickel** - 15716554\n",
    "- **Lucas Keijzer** - 14041073\n",
    "\n",
    "### **Overview**  \n",
    "This notebook contains the code and analysis for **Assignment 3 of Stochastic Simulation**. The code follows the order specified in the assignment guidelines and replicates the experiments conducted in the referenced paper. Each section corresponds to (a) key experiment(s).\n",
    "The entire code required for running this notebook is contained in the repository https://github.com/PaulJungnickel/Stochastic_Simulation_Assignment_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CircleParticleSim import *\n",
    "from scipy.stats import mannwhitneyu\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1) Optimal Particle Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates visual representations of the optimal configurations for \\(n = 11, 12,\\) and \\(50\\). These visualizations depict the best possible outcomes and have been included in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(steps, num_particles, num_runs=10):\n",
    "    \"\"\"\n",
    "    Run the simulation for a given number of particles and store configurations and energies.\n",
    "\n",
    "    Parameters:\n",
    "    - steps: The number of simulation steps to perform.\n",
    "    - num_particles: The number of particles in the simulation.\n",
    "    - num_runs: The number of simulation runs to average results over.\n",
    "\n",
    "    Returns:\n",
    "    - results: A dictionary with averaged metrics (e.g., internal counts, total energy).\n",
    "    - raw_data: A list of dictionaries containing detailed run information.\n",
    "    - energy_examples: A dictionary storing particle locations and corresponding energies.\n",
    "    \"\"\"\n",
    "    internal_counts = []\n",
    "    energies = []\n",
    "    raw_data = []\n",
    "    energy_examples = {\"locations\": [], \"energies\": []}\n",
    "\n",
    "    # Initialize and run the simulation\n",
    "    for run in range(num_runs):\n",
    "        sim = CircleParticleSim(\n",
    "            N=num_particles,\n",
    "            cooling_schedule=paper_cooling_schedule,\n",
    "            step_size_schedule=sqrt_step_size_schedule,\n",
    "            steps=steps\n",
    "        )\n",
    "        sim.run_simulation(steps)\n",
    "\n",
    "        # Calculate floating particles (not on the edge)d\n",
    "        floating_count = np.sum(np.linalg.norm(sim.particle_locations, axis=1) < 0.99)\n",
    "        internal_counts.append(floating_count)\n",
    "        energies.append(sim.E)\n",
    "\n",
    "        # Store raw data\n",
    "        raw_data.append({\n",
    "            \"Run\": run,\n",
    "            \"Floating Count\": floating_count,\n",
    "            \"Energy\": sim.E\n",
    "        })\n",
    "\n",
    "        # Save configurations and energies\n",
    "        energy_examples[\"locations\"].append(sim.particle_locations)\n",
    "        energy_examples[\"energies\"].append(sim.E)\n",
    "\n",
    "    # Calculate metrics for all runs\n",
    "    avg_internal_count = np.mean(internal_counts)\n",
    "    min_internal_count = np.min(internal_counts)\n",
    "    max_internal_count = np.max(internal_counts)\n",
    "\n",
    "    # Compile results into a dictionary\n",
    "    results = {\n",
    "        \"Particles\": num_particles,\n",
    "        \"Internal Count (Avg)\": avg_internal_count,\n",
    "        \"Internal Count (Min)\": min_internal_count,\n",
    "        \"Internal Count (Max)\": max_internal_count,\n",
    "        \"Total Energy (Avg)\": np.mean(energies)\n",
    "    }\n",
    "\n",
    "    print(f\"Completed simulation for {num_particles} particles (averaged over {num_runs} runs).\")\n",
    "\n",
    "    return results, raw_data, energy_examples\n",
    "\n",
    "def plot_selected_configurations(selected_examples):\n",
    "    \"\"\"\n",
    "    Plot configurations for n=11, n=12, and n=50, each showing the lowest energy configuration.\n",
    "\n",
    "    Parameters:\n",
    "    - selected_examples: A dictionary containing particle locations and energies for each particle count.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 24))  # Adjust layout for vertical alignment\n",
    "    particle_counts = [11, 12, 50]\n",
    "\n",
    "    for i, (ax, n_particles) in enumerate(zip(axes, particle_counts)):\n",
    "        # Retrieve locations and energies for the current particle count\n",
    "        locations = selected_examples[n_particles][\"locations\"]\n",
    "        energies = selected_examples[n_particles][\"energies\"]\n",
    "\n",
    "        # Find the best configuration (lowest energy)\n",
    "        best_index = np.argmin(energies)\n",
    "        best_configuration = locations[best_index]\n",
    "        best_energy = energies[best_index]\n",
    "\n",
    "        # Plot the configuration\n",
    "        thetas = np.linspace(0, 2 * np.pi, 100)\n",
    "        ax.plot(np.cos(thetas), np.sin(thetas), linestyle='--', color='gray', linewidth=2, alpha=0.7)\n",
    "        ax.scatter(\n",
    "            best_configuration[:, 0], best_configuration[:, 1],\n",
    "            color='blue', edgecolor='black', s=200, alpha=0.9\n",
    "        )\n",
    "\n",
    "        # Set the title\n",
    "        ax.set_title(\n",
    "            f\"n={n_particles}\\nLowest Energy: {best_energy:.2f}\",\n",
    "            fontsize=24, fontweight='bold', color='navy', pad=30\n",
    "        )\n",
    "\n",
    "        # Styling\n",
    "        ax.set_xlim([-1.2, 1.2])\n",
    "        ax.set_ylim([-1.2, 1.2])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Add a global caption\n",
    "    plt.figtext(\n",
    "        0.5, 0.01,\n",
    "        \"Selected Optimal Configurations: n=11, n=12, n=50 (lowest energy for each).\\n\"\n",
    "        \"Simulated annealing used to minimize energy and arrange particles within a circular boundary.\",\n",
    "        ha='center', fontsize=18, color='darkgray', wrap=True\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def create_and_save_node_energy_table(results, output_file):\n",
    "    \"\"\"\n",
    "    Create a DataFrame for particle counts and their optimal metrics, and save it to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - results: The results data collected from the simulation.\n",
    "    - output_file: Path to save the CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"Node Count and Optimal Metrics Table:\")\n",
    "    print(df)\n",
    "\n",
    "    # Save to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    step_counts = 100000\n",
    "    num_runs = 50\n",
    "    particle_counts = [11, 12, 50]\n",
    "\n",
    "    selected_examples = {}\n",
    "\n",
    "    # Run experiments for the selected particle counts\n",
    "    for n in particle_counts:\n",
    "        print(f\"Running experiment for n={n}...\")\n",
    "        results, raw_data, energy_examples = run_experiment(\n",
    "            steps=step_counts, num_particles=n, num_runs=num_runs\n",
    "        )\n",
    "        selected_examples[n] = energy_examples\n",
    "\n",
    "    # Plot the selected configurations\n",
    "    plot_selected_configurations(selected_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block runs the model for particle counts ranging from \\(n = 9\\) to \\(n = 50\\). It gathers data on particle counts, optimal energies, optimal positional configurations, and the proportional frequency of observing these optimal configurations in the results. A table summarizing these findings has been included in the paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2) Cooling Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block defines the experimental parameters (e.g., number of particles, steps, and runs) and the cooling schedules to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Used:\n",
    "num_particles = 12\n",
    "steps = 10000\n",
    "num_runs = 50\n",
    "\n",
    "\n",
    "# Schedules Used:\n",
    "schedules = [\n",
    "# log_cooling_schedule,\n",
    "# basic_cooling_schedule,\n",
    "paper_cooling_schedule,\n",
    "exponential_cooling_schedule,\n",
    "# linear_cooling_schedule,\n",
    "# quadratic_cooling_schedule,\n",
    "sigmoid_cooling_schedule,\n",
    "inverse_sqrt_cooling_schedule,\n",
    "cosine_annealing_cooling_schedule,\n",
    "# stepwise_cooling_schedule,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block runs simulations for each cooling schedule, evaluates the mean energy, standard deviation of energy, and mean temperature across multiple runs, and saves the results to a `.npy` file for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# generate data\n",
    "for schedule in schedules:\n",
    "    print(f\"Currently running for: {schedule.__name__}\")\n",
    "    mean_energy, std_energy, mean_temperatures = evaluate_multiple_runs(\n",
    "        num_particles, cooling_schedule=schedule, steps=steps, num_runs=num_runs\n",
    "    )\n",
    "    data[schedule.__name__] = {\n",
    "        \"mean_energy\": mean_energy,\n",
    "        \"std_energy\": std_energy,\n",
    "        \"mean_temperatures\": mean_temperatures\n",
    "    }\n",
    "\n",
    "# Save data\n",
    "np.save('data/data-2-{}-{}.npy'.format(num_particles, len(schedules)), data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block loads the saved data from the previous block, plots the temperature and energy evolution over time for each schedule, and highlights the standard deviation. It also includes a zoomed-in inset to visualize the energy behavior in detail over specific ranges of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('data/data-2-{}-{}.npy'.format(num_particles, len(schedules)), allow_pickle=True).item()\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "axins = inset_axes(\n",
    "    axs[1],\n",
    "    width=\"30%\", \n",
    "    height=\"50%\", \n",
    "    loc='upper right'\n",
    ")\n",
    "\n",
    "for schedule_name, results in loaded_data.items():\n",
    "    mean_energy = results[\"mean_energy\"]\n",
    "    std_energy = results[\"std_energy\"]\n",
    "    mean_temperatures = results[\"mean_temperatures\"]\n",
    "    print(f\"min energy: {min(mean_energy)} for schedule: {schedule_name}\")\n",
    "    axs[1].plot(mean_energy, label=schedule_name)\n",
    "    axs[1].fill_between(\n",
    "        range(len(mean_energy)),\n",
    "        mean_energy - std_energy,\n",
    "        mean_energy + std_energy,\n",
    "        alpha=0.3\n",
    "    )\n",
    "    axs[0].plot(mean_temperatures, label=schedule_name)\n",
    "    \n",
    "    axins.plot(mean_energy, label=schedule_name)\n",
    "    axins.fill_between(\n",
    "        range(len(mean_energy)),\n",
    "        mean_energy - std_energy,\n",
    "        mean_energy + std_energy,\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "# Plot for temperature\n",
    "axs[0].set_xlabel(\"Steps\")\n",
    "axs[0].set_ylabel(\"Temperature\")\n",
    "axs[0].set_title(\"Temperature Evolution Over Time\")\n",
    "axs[0].set_xscale('log')\n",
    "# axs[1].set_yscale('log')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot for energy\n",
    "axs[1].set_ylabel(\"Energy\")\n",
    "axs[1].set_title(\"Mean Energy with Standard Deviation Over Time\")\n",
    "axs[1].set_xscale('log')\n",
    "# axs[1].set_yscale('log')\n",
    "# axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "\n",
    "skip_first_steps = 0\n",
    "plt.xlim(left=skip_first_steps)\n",
    "\n",
    "# zoomed in plot\n",
    "axins.set_xlim(10**2, 10**4)\n",
    "axins.set_ylim(119, 121)\n",
    "axins.set_xscale('log')\n",
    "axins.set_yscale('log')\n",
    "axins.grid(True)\n",
    "\n",
    "mark_inset(axs[1], axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical comparison\n",
    "\n",
    "Below some code is written to compare the final step of each schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('data/data-2-{}-{}.npy'.format(num_particles, len(schedules)), allow_pickle=True).item()\n",
    "\n",
    "schedule_names = [\n",
    "\"Paper\",\n",
    "\"Exponential\",\n",
    "\"Sigmoid\",\n",
    "\"Inverse sqrt\",\n",
    "\"Cosine annealing\",\n",
    "]\n",
    "\n",
    "\n",
    "final_mean_energies = []\n",
    "final_std_energies = []\n",
    "labels = []\n",
    "\n",
    "for schedule_name, results in loaded_data.items():\n",
    "    mean_energy = results[\"mean_energy\"]\n",
    "    std_energy = results[\"std_energy\"]\n",
    "    final_mean_energies.append(mean_energy[-1])\n",
    "    final_std_energies.append(std_energy[-1])\n",
    "    labels.append(schedule_name)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot a simple scatter with error bars, since we only have mean and std:\n",
    "plt.errorbar(schedule_names, final_mean_energies, yerr=final_std_energies, fmt='o', capsize=10, linewidth=2, elinewidth= 2)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.ylabel('Final Energy', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('plots/last_step', dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "final_energies = []\n",
    "\n",
    "for schedule_name, stats in loaded_data.items():\n",
    "    energies = stats['energies'][:, -1]  # all runs at final step\n",
    "    labels.append(schedule_name)\n",
    "    final_energies.append(energies)\n",
    "\n",
    "# Determine subplot arrangement\n",
    "n_schedules = len(labels)\n",
    "cols = 2\n",
    "rows = int(np.ceil(n_schedules / cols))\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n",
    "axes = axes.flatten() if n_schedules > 1 else [axes]\n",
    "\n",
    "# Plot a histogram for each schedule\n",
    "bins = 20  \n",
    "for i, (label, energies) in enumerate(zip(labels, final_energies)):\n",
    "    ax = axes[i]\n",
    "    ax.hist(energies, bins=bins, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(label, fontsize=14)\n",
    "    ax.set_xlabel('Final Step Energy')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# If there are fewer schedules than the subplot slots, hide extra axes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the first schedule with all the others\n",
    "first_schedule_label = labels[0]\n",
    "first_schedule_energies = final_energies[0]\n",
    "\n",
    "print(f\"Mann-Whitney U Test results comparing '{first_schedule_label}' to others:\")\n",
    "for label, energies in zip(labels[1:], final_energies[1:]):\n",
    "    # Perform the Mann-Whitney U test\n",
    "    stat, p_value = mannwhitneyu(first_schedule_energies, energies, alternative='two-sided')\n",
    "    \n",
    "    print(f\"Comparison with {label}: U-statistic={stat}, p-value={p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3) Chain Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, simulations are conducted for different chain length scaling factors, with energies recorded for 100 runs at each scaling. Results are saved for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(42)\n",
    "run_count = 20\n",
    "num_particles = 50\n",
    "num_scales = 15\n",
    "chain_lens = np.int64(np.round(np.logspace(1,4,num=num_scales, base=10)))\n",
    "max_cooling_steps = 1000\n",
    "print(chain_lens)\n",
    "\n",
    "def run_scales(num_particles):\n",
    "    arrs = np.zeros([num_scales, run_count]) \n",
    "\n",
    "    for i, chain_len in enumerate(chain_lens):\n",
    "        num_steps = chain_len * max_cooling_steps\n",
    "        # cooling_steps =  int(num_steps/chain_len)\n",
    "        for j in range(run_count):\n",
    "            sim  = CircleParticleSim(num_particles, steps=num_steps, seed=rand.randint(0,2**31-1),\n",
    "                        cooling_schedule = paper_cooling_schedule,\n",
    "                        step_size_schedule = sqrt_step_size_schedule,\n",
    "                        random_step_likelihood=0.2,\n",
    "                        )\n",
    "            sim.run_simulation(max_cooling_steps, chain_len)\n",
    "            arrs[i,j] = sim.E\n",
    "\n",
    "        print(sim.T)\n",
    "\n",
    "        \n",
    "    np.save('data/data-3.1-{}-{}.npy'.format(num_particles, num_scales), arrs)\n",
    "\n",
    "# for num_particles in [22,50,80]:\n",
    "#     run_scales(num_particles)\n",
    "\n",
    "num_scales = 15\n",
    "arrs = np.load('data/data-3.1-50-{}.npy'.format(num_scales))\n",
    "arrs = arrs[:]\n",
    "scales = np.logspace(-2,1,num=num_scales, base=10)\n",
    "scales1 = 100*scales[:]\n",
    "scales1 = np.int64(np.round(np.logspace(1,4,num=num_scales, base=10)))\n",
    "print(arrs.shape)\n",
    "min_energy = np.min(arrs)\n",
    "arrs -= min_energy\n",
    "mean = np.mean(arrs, axis=1)\n",
    "min_energy = 0\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize = (5.5,5), layout='constrained')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "p1 = ax1.plot(scales1, mean, label='mean and range of final energies')\n",
    "perc = 1\n",
    "ax1.fill_between(scales1, np.percentile(arrs, perc, axis=1), np.percentile(arrs, 100-perc, axis=1), alpha=0.3)\n",
    "\n",
    "\n",
    "opt_count = np.count_nonzero((np.abs(arrs - min_energy) < 1e-3), axis=1) / 20\n",
    "p2 = ax2.plot(scales1, opt_count, linestyle='', marker='s', c='tab:orange', label='share of runs that reach the global minimum')\n",
    "ax1.set_xlabel('Markov Chain Length', fontsize=14)\n",
    "ax1.set_ylabel(r'$E - E_{min}$', fontsize=14)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim([1e-6-1e12, 1e2-1e-5])\n",
    "ax2.set_ylim([0,0.99])\n",
    "plt.xscale('log')\n",
    "ax1.yaxis.set_tick_params(labelsize=12, labelcolor='#235b7c') \n",
    "ax2.yaxis.set_tick_params(labelsize=12, labelcolor='#E96700') \n",
    "ax1.xaxis.set_tick_params(labelsize=12, ) \n",
    "ax1.legend(handles=p1+p2, loc='upper center')\n",
    "\n",
    "# fig.savefig('plots/3-50nodes-fin.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4) Neighboring\n",
    "\n",
    "## Direction Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, simulations are performed for different probabilities of random step selection. Final energies are recorded and saved for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(42)\n",
    "run_count = 50\n",
    "num_probs = 20\n",
    "num_particles = 50\n",
    "# probs = np.linspace(0,1,num_probs)\n",
    "\n",
    "chain_len = 1000\n",
    "max_cooling_steps = 300\n",
    "num_steps = chain_len * max_cooling_steps\n",
    "\n",
    "step_size_scheds = [const_step_size_schedule, random_step_size_schedule, sqrt_step_size_schedule]\n",
    "\n",
    "def run_probs(num_particles):\n",
    "    arrs = np.zeros([num_probs, run_count]) \n",
    "\n",
    "    for i, p in enumerate(probs):\n",
    "        for j in range(run_count):\n",
    "            sim  = CircleParticleSim(num_particles, steps=num_steps, seed=rand.randint(0,2**31-1),\n",
    "                        cooling_schedule = paper_cooling_schedule,\n",
    "                        step_size_schedule = sqrt_step_size_schedule,\n",
    "                        random_step_likelihood=p\n",
    "                        )\n",
    "            sim.run_simulation(max_cooling_steps, chain_len)\n",
    "            arrs[i,j] = sim.E\n",
    "\n",
    "        print('.', end='')\n",
    "\n",
    "        \n",
    "    np.save('data/data-4.1-{}-{}.npy'.format(num_particles, num_probs), arrs)\n",
    "\n",
    "\n",
    "# for num_particles in [30, 80, 100]:\n",
    "#     run_probs(num_particles)\n",
    "\n",
    "fig, axs = plt.subplots(1,1,sharex=True, figsize=(5,5),layout='constrained')\n",
    "for i, num_particles in enumerate([22, 50,  80]):\n",
    "    arrs = np.load('data/data-4.1-{}-20.npy'.format(num_particles))\n",
    "    arrs = arrs[:]/2\n",
    "    num_probs = 20\n",
    "    probs = np.linspace(0,1,num_probs)\n",
    "    probs1 = probs[:]\n",
    "    min_energy = np.min(arrs)\n",
    "    arrs = arrs -  min_energy\n",
    "    min_energy=0\n",
    "    print(arrs.shape)\n",
    "    mean = np.mean(arrs, axis=1)\n",
    "    merr = 1.96 / np.sqrt(run_count) *np.std(arrs, axis=1)\n",
    "    axs.errorbar(probs1, mean, merr, linestyle='', marker='o', label='{} particles'.format(num_particles), alpha=0.8)\n",
    "    axs.set_yscale('log')\n",
    "plt.xlabel('P(random direction)', fontsize=14)\n",
    "plt.ylabel(r'$E - E_{min}$', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend()\n",
    "# plt.savefig('plots/4-fin.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Size Schedules Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(42)\n",
    "run_count = 50\n",
    "num_probs = 20\n",
    "num_particles = 50\n",
    "probs = np.linspace(0,1,num_probs)\n",
    "\n",
    "chain_len = 1000\n",
    "max_cooling_steps = 1000\n",
    "num_steps = chain_len * max_cooling_steps\n",
    "\n",
    "step_size_scheds = [const_step_size_schedule, random_step_size_schedule, sqrt_const_step_size_schedule, sqrt_step_size_schedule]\n",
    "\n",
    "def run_single(step_schedule):\n",
    "    arrs = np.zeros([num_probs, run_count]) \n",
    "\n",
    "    for i, p in enumerate(probs):\n",
    "        for j in range(run_count):\n",
    "            sim  = CircleParticleSim(num_particles, steps=num_steps, seed=rand.randint(0,2**31-1),\n",
    "                        cooling_schedule = paper_cooling_schedule,\n",
    "                        step_size_schedule = step_schedule,\n",
    "                        random_step_likelihood=0.2\n",
    "                        )\n",
    "            sim.run_simulation(max_cooling_steps, chain_len)\n",
    "            arrs[i,j] = sim.E\n",
    "\n",
    "        print('.', end='')\n",
    "\n",
    "        \n",
    "    np.save('data/data-4.2-{}-{}.npy'.format(num_particles, num_probs), arrs)\n",
    "\n",
    "\n",
    "# for step_schedule in step_size_scheds:\n",
    "#     run_probs(step_schedule)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,1,sharex=True, figsize=(5,5),layout='constrained')\n",
    "data = []\n",
    "swap = [0,2,1,3]\n",
    "for i, step_schedule in enumerate(step_size_scheds[0:]):\n",
    "    arrs = np.load('data/data-4.3-{}.npy'.format(swap[i]))[0]\n",
    "    arrs = arrs/2\n",
    "    arrs = arrs -  1459.5821\n",
    "    data.append(arrs)\n",
    "\n",
    "labels = ['0.1',  r'$\\sqrt{T}$', 'U(0,1)',r'$U(0,1)\\sqrt{T}$']\n",
    "\n",
    "bplot = plt.boxplot(data, patch_artist=True, tick_labels=labels)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('step size r', fontsize=14)\n",
    "plt.ylabel(r'$E - E_{min}$', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig('plots/4-steps.pdf')\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(i+1, 4):\n",
    "        print(i, j, scipy.stats.mannwhitneyu(data[i], data[j]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
